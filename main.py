import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.preprocessing import StandardScaler , LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
from sklearn.metrics import precision_recall_curve, average_precision_score

df = pd.read_csv("dataset.csv")
print("Dataset loaded successfully.")
print("First 5 rows of the dataset:")
print(df.head())

df['Churn']= df['Churn'].map({'Yes': 1, 'No': 0})

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
df["TotalCharges"] = df["TotalCharges"].fillna(df["TotalCharges"].median())

cat =['Contract', 'PaymentMethod','InternetService', 'OnlineSecurity', 'OnlineBackup',
      'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies','tenure']
for col in cat:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

df = df.fillna(0)
df = df.drop(['customerID','gender','SeniorCitizen','Partner', 'gender',
      'Dependents', 'MultipleLines', 'PhoneService', 'PaperlessBilling'], axis=1)
df = df.replace(' ',np.nan)
X = df.drop('Churn', axis =1)
y = df['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Data split into training and testing sets.")
col = ["tenure", "MonthlyCharges", "TotalCharges"]
Scaler = StandardScaler()
for i in col:
   df[col] = Scaler.fit_transform(df[col])
X_train = Scaler.fit_transform(X_train)
X_test = Scaler.transform(X_test)

model = xgb.XGBClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    use_label_encoder=False,
    eval_metric="logloss"
)

model.fit(X_train, y_train)
print("Model training completed.")

y_pred = model.predict(X_test)
print("Predictions made on the test set.")


print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("\nðŸ“Š Classification Report:\n", classification_report(y_test, y_pred))
print("\nðŸ”Ž Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt


plt.figure(figsize=(6,4))
sns.countplot(x='Churn', data=df)
plt.title('Churn Distribution')
plt.xlabel('Churn')
plt.ylabel('Count')
plt.show()


plt.figure(figsize=(10,8))
corr = df.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Feature Correlation Heatmap')
plt.show()


importances = model.feature_importances_
features = X.columns
plt.figure(figsize=(8,6))
sns.barplot(x=importances, y=features)
plt.title('Feature Importances')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()


plt.figure(figsize=(6,5))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn','Churn'], yticklabels=['No Churn','Churn'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

y_proba = model.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
avg_precision = average_precision_score(y_test, y_proba)

plt.figure(figsize=(8,6))
plt.plot(recall, precision, marker='.', label='XGBoost (AP={:.2f})'.format(avg_precision))
plt.title('Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend()
plt.grid(True)
plt.show()

